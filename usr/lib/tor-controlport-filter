#!/usr/bin/python3 -u

# This filter proxy allows fine-grained access whitelists of commands
# (and their argunents) and events on a per-application basis, stored
# in:
#
#     /etc/tor-controlport-filter.d/
#
# who are pretty self-explanatory as long as you understand the Tor
# ControlPort language. The format is based on YAML where the
# top-level is supposed to be a list, where each element is a
# dictionary looking something like this:
#
#     - name: blabla
#       match-exe-paths:
#         - path_to_executable
#         ...
#       match-users:
#         - user
#         ...
#       match-hosts:
#         - host
#         ...
#       commands:
#         command:
#           - command_arg_rule
#           ...
#         ...
#       confs:
#         conf:
#           - conf_arg_rule
#            ...
#         ...
#       events:
#         event:
#           event_option: event_option_value
#           ...
#         ...
#
# `name` (optional) is a string which gives an internal name, useful
# for debugging. When not given, filters will default to the name of
# the file (excluding extension) they were read from (so there can be
# duplicates!). It is advisable to define one filter per file, and
# give helpful filenames instead of using this field.
#
# A filter is matched if for each of the relevant `match-*` rules at
# least one of the elements match the client. For local (loopback)
# clients the following match rules are needed:
#
# * `match-exe-paths`: a list of strings, each describing the path to
#   the binary or script of the client with `*` matching
#   anything. While this matcher always works for binaries, it only
#   works for scripts with an enabled AppArmor profile (not
#   necessarily enforced, complain mode is good enough).
#
# * `match-users`: a list of strings, each describing the user of the
#   client with `*` matching anything.
#
# For remote (non-local) clients, the following match rules are
# needed:
#
# * match-hosts: a list of strings, each describing the IPv4 address
#   of the client with `*` matching anything.
#
# A filter can serve both local and remote clients by having all
# `match-*` rules.
#
# `commands` (optional) is a list where each item is a dictionary with
# the obligatory `pattern` key, which is a regular expression that is
# matched against the full argument part of the command. The default
# behavior is to just proxy the line through if matched, but it can be
# altered with these keys:
#
# * `replacement`: this rewrites the arguments. The value is a Python
#   format string (str.format()) which will be given the match groups
#   from the match of `pattern`. The rewritten command is then proxied
#   without the need to match any rule. There are also some special
#   patterns that will be replaced as follows:
#
#   - {client-address}: the client's IP address
#   - {client-port}: the client's port
#   - {server-address}: the server's IP address
#   - {server-port}: the server's (listening) port
#
# * `response`: a list of dictionaries, where the `pattern` and
#   `replacement` keys work exactly as for commands arguments, but now
#   for the response. Note that this means that the response is left
#   intact if `pattern` doesn't match it, and if many `pattern`:s
#   match, only the first one (in the order listed) will trigger a
#   replacement.
#
# If a simple regex (as string) is given, it is assumed to be the
# `pattern` which allows a short-hand for this common type of rule.
#
# Note that to allow a command to be run without arguments, the empty
# string must be explicitly given as a `pattern`. Hence, an empty
# argument list does not allow any use of the command.
#
# `confs` (optional) is a dictionary, and it's just syntactic sugar to
# generate GETCONF/SETCONF rules. If a key exists, GETCONF of the
# keyname is allowed, and if it has a non-empty list as value, those
# values are allowed to be set. The empty string means that resetting
# it is allowed. This is very useful for applications that like to
# SETCONF on multiple configurations at the same time.
#
# `events` (optional) is a dictionary where the key represents the
# event. If a key exists the event is allowed. The value is another
# dictionary of options:
#
# * `suppress`: a boolean determining whether we should just fool the
#   client that it has subscribed to the event (i.e. the client
#   request is not filtered) while we suppress them.
#
# * `response`: a dictionary, where the `pattern` and `replacement`
#   keys work exactly as for `response` for commands, but now for the
#   events.
#
# `restrict-stream-events` (optional) is a boolean, and if set any
# STREAM events sent to the client (after it has subscribed to them)
# will be restricted to those belonging to the client itself. This
# option only works for local clients and will be unset for remote
# clients.

import argparse
import glob
import ipaddress
import os.path
import psutil
import re
import socketserver
import stem
import stem.control
import sys
import textwrap
import yaml
import socket
import fcntl
import struct

DEFAULT_LISTEN_ADDRESS = 'localhost'
DEFAULT_LISTEN_PORT = 9051
DEFAULT_COOKIE_PATH = '/var/run/tor/control.authcookie'
DEFAULT_CONTROL_SOCKET_PATH = '/var/run/tor/control'

# Limit the length of a line, to prevent DoS attacks trying to
# crash this filter proxy by sending infinitely long lines.
MAX_LINESIZE = 1024


class NoRewriteMatch(RuntimeError):
    pass


def log(msg):
    print(msg, file=sys.stderr)
    sys.stderr.flush()


def pid_of_laddr(address):
    try:
        return next(conn for conn in psutil.net_connections() \
                    if conn.laddr == address).pid
    except StopIteration:
        return None


def exe_path_of_pid(pid):
    # Here we leverage AppArmor's in-kernel solution for determining
    # the exact executable invoked. Looking at /proc/pid/exe when an
    # interpreted script is running will just point to the
    # interpreter's binary, which is not fine-grained enough, but
    # AppArmor will be aware of which script is running for processes
    # using one of its profiles. However, we fallback to /proc/pid/exe
    # in case there is no AppArmor profile, so the only unsupported
    # mode here is unconfined scripts.
    enabled_aa_profile_re = r'^(/.+) \((?:complain|enforce)\)$'
    with open('/proc/{}/attr/current'.format(str(pid)), "rb") as fh:
        aa_profile_status = str(fh.read().strip(), 'UTF-8')
        exe_path_match = re.match(enabled_aa_profile_re, aa_profile_status)
        if exe_path_match:
            return exe_path_match.group(1)
        else:
            return psutil.Process(pid).exe()

# Override elements 
no_merge_elements = ['suppress','match-hosts']
# Override elements with fixed value 
fixed_value_elements = {'match-exe-paths':'*','match-users':'*'}

def merge_yml(final_obj, parsing_obj):
    # Inputs - 2 dictionaries/list from YML/YAML file
    # "parsing_obj" is parsed and merged into "final_obj" and returned back
    if isinstance(final_obj,dict) and isinstance(parsing_obj,dict):
        for k,v in parsing_obj.items():
            if k not in final_obj:
                final_obj[k] = v
            else:
                if(k in fixed_value_elements):
                    final_obj[k] = fixed_value_elements[k]
                elif(k not in no_merge_elements):
                    final_obj[k] = merge_yml(final_obj[k],v)
                else:
                    pass
                    # Override case 
    else: # Non Dictionary case - LIST 
        pattern_final_obj = {}  
        if(final_obj != parsing_obj): #Only when the LIST are different
            # Specially handle GETINFO case which contains pattern and response 
            for ele in final_obj:
                if(type(ele) is dict):
                    if all (k in ele for k in ('pattern','response')):
                        pattern_final_obj = ele 
          
            # If pattern is same, no need for this whole LIST
            # We will use the higher priority pattern,response
            for ele in parsing_obj:
                if(type(ele) is dict):
                    if all (k in ele for k in ('pattern','response')): 
                        if 'pattern' in pattern_final_obj: 
                            if pattern_final_obj['pattern'] == ele['pattern']:
                                parsing_obj.remove(ele)
                
            # Add without duplicates
            final_obj += [ele for ele in parsing_obj if ele not in final_obj]
    return final_obj 

def match_and_parse_filter(filters, matchers):
    filter_name = None
    allowed_commands = {}
    allowed_events = {}
    restrict_stream_events = False
    matched_filters = [filter_ for filter_ in filters \
                       if all(any(val == expected_val or val == '*' \
                                  for val in filter_.get(key, [])) \
                              for key, expected_val in matchers)]
    if len(matched_filters) > 0:
        matched_filter = matched_filters[0]
        filter_name = matched_filter['name']
        status = 'loaded filter: {}'.format(filter_name)
        if len(matched_filters) > 1:
            status = 'multiple filters matched, ' + status

        # Parse `commands`
        commands = matched_filter.get('commands', {}) or {}
        for cmd in commands:
            allowed_args = commands[cmd]
            # An empty argument list allows nothing, but will
            # make some code below easier than if it can be
            # None as well.
            if allowed_args == None:
                allowed_args = []
            for i in range(len(allowed_args)):
                if isinstance(allowed_args[i], str):
                    allowed_args[i] = {'pattern': allowed_args[i]}
            allowed_commands[cmd.upper()] = allowed_args

        # Prase `confs`, which is just syntactic sugar
        confs = matched_filter.get('confs', {}) or {}
        combined_getconf_rule = {'pattern': "(" + "|".join([
            key for key in confs]) + ")"}
        setconf_reset_part = "\s*|\s*".join([
            key for key in confs if isinstance(confs[key], list) and \
                                    '' in confs[key]]
        )
        setconf_assignment_part = "\s*|\s*".join([
            "{}{}".format(
                key, "=({})".format("|".join(confs[key]))
            ) for key in confs if isinstance(confs[key], list) and \
                                  len(confs[key]) > 0])
        setconf_parts = []
        for part in [setconf_reset_part, setconf_assignment_part]:
            if part and part != '':
                setconf_parts.append(part)
        combined_setconf_rule = {
            'pattern': "({})+".format("\s*|\s*".join(setconf_parts))
        }
        for cmd, rule in [('GETCONF', combined_getconf_rule),
                          ('SETCONF', combined_setconf_rule)]:
            if rule['pattern'] != "()+":
                if cmd not in allowed_commands:
                    allowed_commands[cmd] = []
                allowed_commands[cmd].append(rule)

        # Parse `events`
        events = matched_filter.get('events', {}) or {}
        for event in events:
            opts = events[event]
            # Same as for the `commands` argument list, let's
            # add an empty dict to simplify later code.
            if opts == None:
                opts = {}
            allowed_events[event.upper()] = opts

        # Parse `restrict-stream-events`
        restrict_stream_events = bool(matched_filter.get(
            'restrict-stream-events', False
        ))
    else:
        status = 'no matching filter found, using an empty one'
    return (status, filter_name, allowed_commands,
            allowed_events, restrict_stream_events)

def get_ip_address(ifname):
    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    return socket.inet_ntoa(fcntl.ioctl(
        s.fileno(),
        0x8915,  # SIOCGIFADDR
        struct.pack('256s', bytes(ifname[:15], 'utf-8'))
    )[20:24])

def handle_controlport_session(controller, readh, writeh, client_desc, client_pid, client_address, server_address, allowed_commands, allowed_events, restrict_stream_events = False):

    def _log(line, format_multiline=False, sep = ': '):
        line = line.strip()
        if format_multiline and "\n" in line:
            sep += "(multi-line)\n"
            line = textwrap.indent(line, ' '*4)
        log(client_desc + sep + line)

    def debug_log_send(line):
        if global_args.print_responses:
            _log(line, format_multiline=True, sep=': <- ')

    def debug_log_recv(line):
        if global_args.print_requests:
            _log(line, format_multiline=True, sep=': -> ')

    def debug_log_rewrite(kind, old, new):
        if kind not in ['command', 'received event', 'response'] or \
           (kind == 'command' and not global_args.print_responses) or \
           (kind in ['received event', 'response'] and \
            not global_args.print_requests):
            return
        if new != old:
            old = textwrap.indent(old.strip(), ' '*4)
            new = textwrap.indent(new.strip(), ' '*4)
            _log("rewrote {}:\n{}\nto:\n{}".format(kind, old, new),
                 format_multiline=False)

    def respond(line, raw=False):
        if line.isspace(): return
        debug_log_send(line)
        writeh.write(bytes(line, 'ascii'))
        if not raw: writeh.write(bytes("\r\n", 'ascii'))
        writeh.flush()

    def get_rule(cmd, arg_str):
        allowed_args = allowed_commands.get(cmd, [])
        return next((rule for rule in allowed_args \
                     if re.match(rule['pattern'] + "$", arg_str)), None)

    def proxy_line(line, args_rewriter = None, response_rewriter = None):
        if args_rewriter:
            new_line = args_rewriter(line)
            debug_log_rewrite('command', line, new_line)
            line = new_line
        response = controller.msg(line.strip()).raw_content()
        if response_rewriter:
            new_response = response_rewriter(response)
            debug_log_rewrite('response', response, new_response)
            response = new_response
        respond(response, raw=True)

    def filter_line(line):
        _log("command filtered: {}".format(line))
        respond("510 Command filtered")

    def rewrite_line(replacers, line):
        builtin_replacers = {
            'client-address': client_address[0],
            'client-port':    str(client_address[1]),
            'server-address': server_address[0],
            'server-port':    str(server_address[1]),
        }
        terminator = ''
        if line[-2:] == "\r\n":
            terminator = "\r\n"
            line = line[:-2]
        for r in replacers:
            log("line: '{}'".format(line))
            log("r: '{}'".format(r))
            log("pattern: '{}'".format(r['pattern']))
            log("replacement: '{}'".format(r['replacement']))
            match = re.match(r['pattern'] + "$", line)
            log("match: '{}'".format(match))
            if match:
                return r['replacement'].format(
                    *match.groups(), **builtin_replacers
                ) + terminator
        raise NoRewriteMatch()

    def rewrite_matched_line(replacers, line):
        try:
            return rewrite_line(replacers, line)
        except NoRewriteMatch:
            return line

    def rewrite_matched_lines(replacers, lines):
        split_lines = lines.strip().split("\r\n")
        return "\r\n".join([rewrite_matched_line(replacers, line) \
                            for line in split_lines]) + "\r\n"

    def event_cb(event, event_rewriter = None):
        if restrict_stream_events and \
           isinstance(event, stem.response.events.StreamEvent) and \
           not global_args.disable_filtering:
            if event.id not in client_streams:
                if event.status in [stem.StreamStatus.NEW,
                                    stem.StreamStatus.NEWRESOLVE] and \
                   client_pid == pid_of_laddr((event.source_address,
                                               event.source_port)):
                    client_streams.add(event.id)
                else:
                    return
            elif event.status in [stem.StreamStatus.FAILED,
                                  stem.StreamStatus.CLOSED]:
                client_streams.remove(event.id)
        raw_event_content = event.raw_content()
        if event_rewriter:
            new_raw_event_content = event_rewriter(raw_event_content)
            debug_log_rewrite(
                'received event', raw_event_content, new_raw_event_content
            )
            raw_event_content = new_raw_event_content
        respond(raw_event_content, raw=True)

    def update_event_subscriptions(events):
        if not global_args.disable_filtering and \
           any(event not in allowed_events for event in events):
            filter_line(line)
            return
        for listener, event in subscribed_event_listeners:
            if event not in events:
                controller.remove_event_listener(listener)
                subscribed_event_listeners.remove((listener, event))
                if global_args.print_responses:
                    _log("unsubscribed to event '{}'".format(event))
        for event in events:
            if any(event == event_ for _, event_ in subscribed_event_listeners):
                if global_args.print_responses:
                    _log("already subscribed to event '{}'".format(event))
                continue
            rule = allowed_events.get(event, {}) or {}
            if not rule.get('suppress', False) or \
               global_args.disable_filtering:
                event_rewriter = None
                if 'response' in rule:
                    replacers = rule['response']
                    def _event_rewriter(line):
                        return rewrite_matched_line(replacers, line)
                    event_rewriter = _event_rewriter
                def _event_cb(event):
                    event_cb(event, event_rewriter=event_rewriter)
                controller.add_event_listener(
                    _event_cb, getattr(stem.control.EventType, event)
                )
                subscribed_event_listeners.append((_event_cb, event))
                if global_args.print_responses:
                    _log("subscribed to event '{}'".format(event))
            else:
                if global_args.print_responses:
                    _log("suppressed subscription to event '{}'".format(event))
        respond("250 OK")

    subscribed_event_listeners = []
    client_streams = set()
    while True:
        binary_line = readh.readline(MAX_LINESIZE)
        if binary_line == b'':
            # Deal with clients that close the socket without a QUIT.
            break
        line = str(binary_line, 'ascii')
        if line.isspace():
            _log('ignoring received empty (or whitespace-only) line')
            continue
        match = re.match(r'(\S+)(\s*)([^\r\n]*)\r?\n$', line)
        if not match:
            _log("received bad line (escapes made explicit): " + repr(line))
            # Hopefully the next line is ok...
            continue
        debug_log_recv(line)
        cmd, cmd_arg_sep, arg_str = match.groups()
        args = arg_str.split()
        cmd = cmd.upper()

        if cmd == "PROTOCOLINFO":
            # Stem call PROTOCOLINFO before authenticating. Tell the
            # client that there is no authentication.
            respond("250-PROTOCOLINFO 1")
            respond("250-AUTH METHODS=NULL")
            respond("250-VERSION Tor=\"{}\"".format(controller.get_version()))
            respond("250 OK")

        elif cmd == "AUTHENTICATE":
            # We have already authenticated, and the filtered port is
            # access-restricted according to our filter instead.
            respond("250 OK")

        elif cmd == "QUIT":
            respond("250 closing connection")
            break

        elif cmd == "SETEVENTS":
            # The control language doesn't care about case for
            # the event type.
            events = [event.upper() for event in args]
            update_event_subscriptions(events)

        else:
            rule = get_rule(cmd, arg_str)
            if rule == None and global_args.disable_filtering:
                rule = {}
            if rule != None:
                args_rewriter = None
                response_rewriter = None

                if 'response' in rule:
                    def _response_rewriter(lines):
                        return rewrite_matched_lines(rule['response'], lines)
                    response_rewriter = _response_rewriter

                if 'replacement' in rule:
                    def _args_rewriter(line):
                        # We also want to match the command in `line`
                        # and add it back to the replacement string.
                        # We make sure to keep the exact white spaces
                        # separating the command and arguments, to not
                        # rewrite the line unnecessarily.
                        prefix = cmd + cmd_arg_sep
                        replacer = {
                            'pattern':     prefix + rule['pattern'],
                            'replacement': prefix + rule['replacement']
                        }
                        return rewrite_line([replacer], line)
                    args_rewriter = _args_rewriter

                proxy_line(line, args_rewriter=args_rewriter,
                           response_rewriter=response_rewriter)
            else:
                filter_line(line)


class FilteredControlPortProxyHandler(socketserver.StreamRequestHandler):

    def setup(self):
        super(type(self), self).setup()
        self.filters = []
        
        filter_files_set1 = glob.glob('/etc/tor-controlport-filter.d/*.yml')
        filter_files_set1.sort(reverse = True) 
        filter_files_set2 = glob.glob('/usr/local/etc/tor-controlport-filter.d/*.yml')
        filter_files_set2.sort(reverse = True)
        filter_files = filter_files_set1 + filter_files_set2  
        
        merged_filter_dict = {} 
        for filter_file in filter_files: 
            try:
                with open(filter_file, "rb") as fh:
                    filters = yaml.load(fh.read())
                    for i in range(len(filters)):
                        merged_filter_dict = merge_yml(merged_filter_dict,filters[i]) 
            except (yaml.parser.ParserError, yaml.scanner.ScannerError):
                log("filter '{}' has bad YAML and was not loaded!"
                    .format(filter_file))
        merged_filter = [merged_filter_dict,] 
        name = 'merged_filter_files' 
        for filter_ in merged_filter:
            if name not in filter_:
                filter_['name'] = "merged_filter_files" 
        self.filters = merged_filter
        log("Merged Filter File is {} \n".format(merged_filter)) 

    def connect_to_real_control_port(self):
        with open(global_args.control_cookie_path, "rb") as f:
            cookie = f.read()
        controller = stem.control.Controller.from_socket_file(
            global_args.control_socket_path
        )
        controller.authenticate(cookie)
        return controller

    def handle(self):
        client_host = self.client_address[0]
        local_connection = ipaddress.ip_address(client_host).is_loopback
        if local_connection:
            client_pid = pid_of_laddr(self.client_address)
            # Deal with the race between looking up the PID, and the
            # client being killed before we find the PID.
            if not client_pid: return
            client_exe_path = exe_path_of_pid(client_pid)
            client_user = psutil.Process(client_pid).username()
            matchers = [
                ('match-exe-paths', client_exe_path),
                ('match-users',     client_user),
            ]
        else:
            client_pid = None
            matchers = [
                ('match-hosts', client_host),
            ]
        status, filter_name, allowed_commands, \
            allowed_events, restrict_stream_events = \
                match_and_parse_filter(self.filters, matchers)
        if local_connection:
            client_desc = '{} (pid: {}, user: {}, port: {}, filter: {})'.format(
                client_exe_path, client_pid, client_user,
                self.client_address[1], filter_name
            )
        else:
            client_desc = '{1}:{2} (filter: {0})'.format(
                filter_name, *self.client_address
            )
        if restrict_stream_events and not local_connection:
            log(
                "{}: filter '{}' has `restrict-stream-events` set " +
                "and we are remote so the option was disabled"
                .format(client_desc, filter_name)
            )
            restrict_stream_events = False
        log('{} connected: {}'.format(client_desc, status))
        if global_args.debug:
            log('Final rules:')
            log(yaml.dump({
                'commands': allowed_commands,
                'events': allowed_events,
                'restrict-stream-events': restrict_stream_events,
            }))
        disconnect_reason = "client quit"
        controller = None
        try:
            controller = self.connect_to_real_control_port()
            handle_controlport_session(controller, self.rfile, self.wfile,
                                       client_desc, client_pid,
                                       self.client_address,
                                       self.server.server_address,
                                       allowed_commands, allowed_events,
                                       restrict_stream_events
            )
        except (ConnectionResetError, BrokenPipeError) as err:
            # Handle clients disconnecting abruptly
            disconnect_reason = str(err)
        except stem.SocketError:
            # Handle client closing its socket abruptly
            disconnect_reason = "Client closed its socket"
        except stem.SocketClosed:
            # Handle Tor closing its socket abruptly
            disconnect_reason = "Tor closed its socket"
        finally:
            if controller:
                controller.close()
            log('{} disconnected: {}'.format(client_desc, disconnect_reason))


class FilteredControlPortProxy(socketserver.ThreadingTCPServer):
    # So we can restart when the listening port if in TIME_WAIT state
    # after an abrupt shutdown.
    allow_reuse_address = True
    # So all server threads immediately quit when the main thread
    # quits.
    daemon_threads = True


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--listen-address",
        type=str, metavar='ADDR', default=DEFAULT_LISTEN_ADDRESS,
        help="specifies the address on which the server listens " +
             "(default: {})".format(DEFAULT_LISTEN_ADDRESS)
    )
    parser.add_argument(
        "--listen-port",
        type=int, metavar='PORT', default=DEFAULT_LISTEN_PORT,
        help="specifies the port on which the server listens " +
             "(default: {})".format(DEFAULT_LISTEN_PORT)
    )
    
    parser.add_argument(
        "--listen-interface",
        type=str, metavar='INTERFACE',
        help="specifies the interface on which the server listens " +
             "(default: NULL)"
    )

    parser.add_argument(
        "--control-cookie-path",
        type=str, metavar='PATH', default=DEFAULT_COOKIE_PATH,
        help="specifies the path to Tor's control authentication cookie " +
             "(default: {})".format(DEFAULT_COOKIE_PATH)
    )
    parser.add_argument(
        "--control-socket-path",
        type=str, metavar='PATH', default=DEFAULT_CONTROL_SOCKET_PATH,
        help="specifies the path to Tor's control socket " +
             "(default: {})".format(DEFAULT_CONTROL_SOCKET_PATH)
    )
    parser.add_argument(
        "--complain",
        action='store_true', default=False,
        help="disables all filtering and just prints the commands sent " +
             "by the client"
    )
    parser.add_argument(
        "--debug",
        action='store_true', default=False,
        help="prints all requests and responses"
    )
    # We put the argparse results in the global scope since it's
    # awkward to extend socketserver so additional data can be sent to
    # the request handler, where we need access to the arguments.
    global global_args
    global_args = parser.parse_args()
    # Deal with overlapping functionality between arguments
    global_args.__dict__['disable_filtering'] = global_args.complain
    global_args.__dict__['print_requests'] = global_args.complain or \
                                             global_args.debug
    global_args.__dict__['print_responses'] = global_args.debug
  
    if global_args.listen_interface:
        ip_address = get_ip_address(global_args.listen_interface)
        if global_args.debug:
            log("IP address for interface {} : {}".format( 
                                 global_args.listen_interface,ip_address))
    else:
        ip_address = global_args.listen_address
    address = (ip_address, global_args.listen_port)
 
    server = FilteredControlPortProxy(address, FilteredControlPortProxyHandler)
    log("Tor control port filter started, listening on {}:{}".format(*address))
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        pass


if __name__ == "__main__":
    main()
